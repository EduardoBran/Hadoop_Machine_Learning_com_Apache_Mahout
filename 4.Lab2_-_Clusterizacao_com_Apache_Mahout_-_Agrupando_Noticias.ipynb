{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70f743d",
   "metadata": {},
   "source": [
    "# <center><span style=\"font-size: 42px;color: darkgreen;\">Lab2: Clusterização</center></span>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## Contexto\n",
    "\n",
    "Neste laboratório, exploraremos o conceito de **Clusterização**, uma técnica de **aprendizagem não supervisionada**. Foi fornecido um conjunto de dados composto por 7 arquivos `.txt`, cada um contendo uma notícia. O **objetivo** deste laboratório é utilizar algoritmos de clusterização para identificar automaticamente grupos de notícias semelhantes, sem conhecimento prévio de rótulos ou categorias específicas.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Problema de Negócio\n",
    "\n",
    "Dada a necessidade de organizar e categorizar grandes volumes de notícias, este laboratório busca **resolver o problema de agrupar notícias semelhantes em clusters**. Com essa abordagem, é possível identificar temas ou tópicos recorrentes, facilitando a análise e o entendimento dos conteúdos sem intervenção manual. A solução é especialmente útil para empresas de mídia, plataformas de notícias e qualquer organização que precise organizar informações textuais em larga escala de forma eficiente.\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# <center>Iniciando o Laboratório</center>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "\n",
    "## 1 Iniciando os Serviços\n",
    "\n",
    "<br>\n",
    "\n",
    "- **1.1 Iniciar o HDFS (NameNode, DataNode, SecondaryNameNode)**:\n",
    "   ```bash\n",
    "   start-dfs.sh  |  stop-dfs.sh\n",
    "   ```\n",
    "- **1.2 Iniciar o YARN (ResourceManager, NodeManager)**:\n",
    "   ```bash\n",
    "   start-yarn.sh  |  stop-yarn.sh\n",
    "   ```\n",
    "- **1.3 Verificando serviços**:\n",
    "   ```bash\n",
    "   jps\n",
    "   ```\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## 2. Gravando os Dados no Cluster HDFS\n",
    "\n",
    "<br>\n",
    "\n",
    "Nesta etapa, vamos copiar os arquivos do sistema local para o `HDFS` para que possam ser processados pelo `Mahout`.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 2.1 Criando Diretórios no HDFS\n",
    "\n",
    "No terminal digitar os comandos:\n",
    "\n",
    "```bash\n",
    "hdfs dfs -mkdir /mahout/clustering\n",
    "hdfs dfs -mkdir /mahout/clustering/data\n",
    "```\n",
    "\n",
    "#### 2.2 Lista os arquivos e diretórios no HDFS raiz.\n",
    "\n",
    "```bash\n",
    "hdfs dfs -ls /\n",
    "```\n",
    "\n",
    "#### 2.3 Copiando dados do sistema local para o HDFS\n",
    "\n",
    "No diretório onde estão as pastas `ham` e `spam` ir ao terminal e digitar:\n",
    "\n",
    "```bash\n",
    "hdfs dfs -copyFromLocal news/* /mahout/clustering/data\n",
    "```\n",
    "\n",
    "#### 2.4 Verificar conteúdo\n",
    "\n",
    "```bash\n",
    "hdfs dfs -ls /mahout/clustering/data\n",
    "hdfs dfs -cat /mahout/clustering/data/*\n",
    "```\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "## 3. Pré-Processamento dos Dados com Apache Mahout\n",
    "\n",
    "> **Importante**: O pré-processamento a seguir é específico para dados em formato de texto, como o conjunto de dados atual, que contém notícias armazenadas em arquivos `.txt`. A etapa de pré-processamento converte esses textos em um formato numérico que o Mahout pode utilizar para aplicar algoritmos de clusterização.\n",
    "\n",
    "> O **objetivo do pré-processamento** é transformar as notícias em representações numéricas (vetores esparsos) usando o **TF-IDF** (Term Frequency-Inverse Document Frequency). Esses vetores ajudam o algoritmo de clusterização a identificar padrões e similaridades entre as notícias.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 3.1 Converter Dados para Formato de Sequence (obrigatório quando se trabalha com Mahout)\n",
    "\n",
    "O primeiro passo no `Mahout` é transformar os dados de texto em uma **sequence file**, um formato binário que facilita o processamento distribuído no `Hadoop`.\n",
    "\n",
    "```bash\n",
    "mahout seqdirectory -i /mahout/clustering/data -o /mahout/clustering/kmeansseq\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 3.2 Criar a Matriz Esparsa com Vetores TF-IDF\n",
    "\n",
    "Com os dados em formato Sequence, o próximo passo é converter essas sequências para uma matriz esparsa de vetores **TF-IDF**. O TF-IDF mede a importância de cada termo em relação ao documento e ao conjunto total de documentos, permitindo que o Mahout utilize essas informações para agrupar notícias semelhantes.\n",
    "\n",
    "```bash\n",
    "mahout seq2sparse -i /mahout/clustering/kmeansseq -o /mahout/clustering/kmeanssparse\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 3.2 Verificar Saída da Matriz Esparsa\n",
    "\n",
    "Após a criação da matriz esparsa, verifique o diretório de saída para confirmar que os vetores **TF-IDF** foram gerados corretamente:\n",
    "\n",
    "```bash\n",
    "hdfs dfs -ls /mahout/clustering/kmeanssparse\n",
    "```\n",
    "<br>\n",
    "\n",
    "A saída mostra os arquivos e diretórios gerados para representar os dados de texto em formato de vetores esparsos:\n",
    "\n",
    "- **df-count**: Contagem de documentos por termo (usado para calcular **IDF**).\n",
    "- **dictionary.file-0**: Mapeamento de termos para índices únicos.\n",
    "- **frequency.file-0**: Frequência de termos no conjunto de dados.\n",
    "- **tf-vectors**: Vetores de frequência dos termos (**TF**) por documento.\n",
    "- **tfidf-vectors**: Vetores **TF-IDF**, que indicam a relevância de cada termo.\n",
    "- **tokenized-documents**: Documentos tokenizados em palavras.\n",
    "- **wordcount**: Contagem total de palavras. (`hadoop fs -text /mahout/output/sparseoutput/wordcount/*`)\n",
    "\n",
    "<br>\n",
    "\n",
    "Esses dados indicam que o pré-processamento está completo e pronto para uso em modelos de aprendizado de máquina.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "## 4. Divisão dos Dados em Treino e Teste\n",
    "\n",
    "<br>\n",
    "\n",
    "Neste laboratório, não há divisão de dados em treino e teste porque estamos utilizando **aprendizado não supervisionado**.\n",
    "\n",
    "O **objetivo** aqui é identificar grupos ou padrões nos dados sem rótulos pré-definidos.\n",
    "\n",
    "No caso do **K-mean**s, o algoritmo é aplicado ao conjunto completo de dados para formar clusters, agrupando itens semelhantes. Como não estamos tentando prever uma categoria específica com base em rótulos conhecidos, não é necessário separar os dados para avaliação.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## 5. Treinando o Modelo com Dados no Cluster HDFS\n",
    "\n",
    "<br>\n",
    "\n",
    "Agora que os dados foram pré-processados e convertidos para o formato adequado, podemos aplicar o algoritmo de **K-means** usando o **Apache Mahout**. Este processo cria clusters de notícias semelhantes com base nos vetores **TF-IDF** dos termos em cada documento, agrupando-os em três categorias (conforme definido pelo parâmetro `-k 3`). Os centroids e os clusters resultantes serão armazenados no `HDFS` para análise posterior.\n",
    "\n",
    "```bash\n",
    "# Explicando os parâmetros\n",
    "#\t-i\tdiretório com arquivos de entrada\n",
    "#\t-c\tdiretório de destino para os centroids\n",
    "#\t-o\tdiretório de saída\n",
    "#\t-k\tnúmero de clusters\n",
    "#\t-ow\toverwrite \n",
    "#\t-x\tnúmero de iterações\n",
    "#\t-dm\tmedida de distância\n",
    "mahout kmeans -i /mahout/clustering/kmeanssparse/tfidf-vectors/ -c /mahout/clustering/kmeanscentroids -cl -o /mahout/clustering/kmeansclusters -k 3 -ow -x 10 -dm org.apache.mahout.common.distance.CosineDistanceMeasure\n",
    "\n",
    "# Visualiza os arquivos no HDFS\n",
    "hdfs dfs -ls /mahout/clustering/kmeansclusters\n",
    "```\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## 6. Testando e Avaliando o Modelo\n",
    "\n",
    "<br>\n",
    "\n",
    "Após o treinamento do modelo `K-means`, **é possível exportar os clusters para um arquivo de texto e visualizar os resultados**. Isso permite entender o conteúdo de cada cluster e verificar os documentos atribuídos a cada grupo.\n",
    "\n",
    "```bash\n",
    "# Dump dos clusters para um arquivo texto\n",
    "mahout clusterdump -i /mahout/clustering/kmeansclusters/clusters-1-final -o clusterdump.txt -p /mahout/clustering/kmeansclusters/clusteredPoints/ -d /mahout/clustering/kmeanssparse/dictionary.file-0 -dt sequencefile -n 20 -b 100\n",
    "\n",
    "# Visualiza os clusters (salvo na pasta home da máquinalocal)\n",
    "cat clusterdump.txt\n",
    "```\n",
    "<br>\n",
    "\n",
    "Esse passo finaliza o laboratório e permite que você observe como os documentos foram agrupados em diferentes clusters com base em sua similaridade.\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "# Fim!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb3f35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
